{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning in Python with scikit-learn\n",
    "\n",
    "scikit-learn (`sklearn`) provides a user-friendly, but powerful way to conduct machine learning\n",
    "analyses in Python. It simplifies most standard machine learning tasks - training many kinds of\n",
    "classifiers, predicting new results, obtaining cross-validated scores, feature extraction -\n",
    "with one consistent API; you only have to learn one way of calling the tools.\n",
    "\n",
    "Here, we provide an ultra brief intro to scikit-learn on a digit classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the `digits` dataset\n",
    "from sklearn.datasets import load_digits\n",
    "data = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[\"DESCR\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Machine Learning, the outcomes are typically called `y` and the predictors `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data[\"data\"], data[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the predictors (with matplotlib):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(data[\"images\"][0], cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same values as in `data[\"images\"]` are also stored in Â´data[\"data\"]`, and thus now `X`,\n",
    "albeit in a dfifferent shape (as an 1x64 vector):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X[0].reshape((8, 8)), cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the corresponding outcomes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some more ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X[1].reshape((8, 8)), cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting a few ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=10, nrows=3, figsize=(15, 5))\n",
    "\n",
    "for ii, (ax, im, y_) in enumerate(zip(axes.flatten(), X, y)):\n",
    "    ax.imshow(im.reshape((8, 8)), cmap=\"Greys\")\n",
    "    ax.set_title(y_)\n",
    "    ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train a simple linear classifier to predict $y$ from $X$, i.e., read the digit based off of the pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create an instance of a Logistic Regression Classifier ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = LogisticRegression(dual=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and fit it to the training set (i.e., we learn the patterns required to predict digits)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What has the classifier learned? We can visualise the learned patterns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est.coef_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=10, nrows=1, figsize=(15, 3))\n",
    "for ax, pattern in zip(axes.flatten(), est.coef_):\n",
    "    ax.imshow((pattern).reshape((8, 8)), cmap=\"RdBu_r\", vmin=-1, vmax=1)\n",
    "    ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier has a `fit` and a `predict` method. We can print its predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=10, nrows=3, figsize=(15, 5))\n",
    "\n",
    "for ii, (ax, im) in enumerate(zip(axes.flatten(), X)):\n",
    "    ax.imshow(im.reshape((8, 8)), cmap=\"Greys\")\n",
    "    predicted = est.predict(im[np.newaxis, :])[0]\n",
    "    ax.set_title(predicted)\n",
    "    ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But this is testing on the training set. We need to separate testing and training!\n",
    "For that, we can use the `cross_val_predict` helper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = cross_val_predict(est, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=10, nrows=3, figsize=(15, 5))\n",
    "\n",
    "for ii, (ax, im, y_pred) in enumerate(zip(axes.flatten(), X, predictions)):\n",
    "    ax.imshow(im.reshape((8, 8)), cmap=\"Greys\")\n",
    "    ax.set_title(y_pred)\n",
    "    ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can use the `cross_val_score` function to check the predictive accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(est, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we want to try a more powerful classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... same API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(rf, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can perform complex feature preprocessing techniques with sklearn, with a similar API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(X.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scaled = MinMaxScaler((0, 1)).fit_transform(X)\n",
    "plt.hist(X.flatten(), label=\"original\")\n",
    "plt.hist(x_scaled.flatten(), label=\"scaled\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for something more interesting ... remember what the digits look like!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=10, nrows=3, figsize=(15, 5))\n",
    "\n",
    "for ii, (ax, im, y_) in enumerate(zip(axes.flatten(), X, y)):\n",
    "    ax.imshow(im.reshape((8, 8)), cmap=\"Greys\")\n",
    "    ax.set_title(y_)\n",
    "    ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use non-negative matrix factorization for unsupervised extraction of consistent patterns in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA, NMF\n",
    "\n",
    "nmf = NMF(n_components=10)\n",
    "X2 = nmf.fit(x_scaled).transform(x_scaled)\n",
    "X2 = nmf.inverse_transform(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=10, nrows=4, figsize=(15, 8))\n",
    "\n",
    "for ii, (ax, im, y_) in enumerate(zip(axes.flatten()[:30], X2, y)):\n",
    "    ax.imshow(im.reshape((8, 8)), cmap=\"Greys\")\n",
    "    ax.set_title(y_)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "for jj, comp in enumerate(nmf.components_):\n",
    "    ax = axes.flatten()[ii + jj + 1]\n",
    "    ax.imshow(comp.reshape((8, 8)), cmap=\"Greys\")\n",
    "    ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can chain preprocessing stages and various classifiers ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "est_pipeline = make_pipeline(MinMaxScaler((0, 1)), NMF(n_components=35), LinearSVC())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(est_pipeline, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and with the same API, you could do Machine Learning on any kind of data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:mne]",
   "language": "python",
   "name": "conda-env-mne-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
