{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Python for visualizing neuroimaging data\n",
    "\n",
    "The primary goal of this section is to become familiar with loading, modifying, saving, and visualizing neuroimages in Python. A secondary goal is to develop a conceptual understanding of the data structures involved, to facilitate diagnosing problems in data or analysis pipelines.\n",
    "\n",
    "To these ends, we'll be exploring two libraries: [nibabel](http://nipy.org/nibabel/) and [nilearn](https://nilearn.github.io/). Each of these projects has excellent documentation. While this should get you started, it is well worth your time to look through these sites.\n",
    "\n",
    "In this notebook we will cover: [nilearn](https://nilearn.github.io/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nilearn\n",
    "\n",
    "[Nilearn](http://nilearn.github.io/index.html) labels itself as: *A Python module for fast and easy statistical learning on NeuroImaging data. It leverages the scikit-learn Python toolbox for multivariate statistics with applications such as predictive modelling, classification, decoding, or connectivity analysis.*\n",
    "\n",
    "But it's much more than that. It is also an excelent library to **manipulate** (e.g. resample images, smooth images, ROI extraction, etc.) and **visulaize** your neuroimages.\n",
    "\n",
    "So let's visit all three of those domains:\n",
    "\n",
    "1. Image manipulation\n",
    "2. Image visualization\n",
    "3. Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image settings\n",
    "import pylab as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "out_dir = '/tmp'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Image manipulation with `nilearn`\n",
    "\n",
    "### Let's create a mean image\n",
    "\n",
    "Let's revisit the example from above and see how nilearn can create a **mean image** in just one line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import image as nli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = nli.mean_img('/data/ds000114/sub-01/ses-test/func/sub-01_ses-test_task-fingerfootlips_bold.nii.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect! What else can we do with the `image` module? Let's see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted([f for f in nli.__dict__ if '__' not in f])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resample image to a template\n",
    "So, let's try **`resample_to_img`**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = nli.mean_img('/data/ds000114/sub-01/ses-test/func/sub-01_ses-test_task-fingerfootlips_bold.nii.gz')\n",
    "t1 = nli.load_img('/data/ds000114/sub-01/ses-test/anat/sub-01_ses-test_T1w.nii.gz')\n",
    "print([mean.shape, t1.shape])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's resample the t1 image to the mean image\n",
    "resampled_t1 = nli.resample_to_img(t1, mean)\n",
    "resampled_t1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image size of the resampled t1 image seems to right, but how does it look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import plotting\n",
    "plotting.plot_anat(t1, title='original t1', display_mode='z')\n",
    "plotting.plot_anat(resampled_t1, title='resampled t1', display_mode='z')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smooth an image\n",
    "Cool! What about **`smooth_img`**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fwhm in range(0, 11, 5):\n",
    "    smoothed_img = nli.smooth_img(mean, fwhm)\n",
    "    plotting.plot_epi(smoothed_img, title=\"Smoothing %imm\" % fwhm,\n",
    "                     display_mode='z', cmap=plt.cm.magma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean an image to improve SNR\n",
    "\n",
    "As simple as that. Before we continue, let's also look at **`clean_img`**. A function to improve the SNR of your fMRI signals. This can be done with one or more of the following options:\n",
    "\n",
    "- detrend\n",
    "- standardize\n",
    "- remove confounds\n",
    "- low- and high-pass filter\n",
    "\n",
    "Low-pass filtering improves specificity. High-pass filtering should be kept small, to keep some sensitivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's load again a functional image\n",
    "func = nli.load_img('/data/ds000114/sub-01/ses-test/func/sub-01_ses-test_task-fingerfootlips_bold.nii.gz')\n",
    "TR = func.header['pixdim'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As a first step, let's just detrend the image\n",
    "func_d = nli.clean_img(func, detrend=True, standardize=False, t_r=TR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the original and detrended timecourse of a random voxel\n",
    "x, y, z = [31, 14, 7]\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(np.transpose(func.get_data()[x, y, z, :]))\n",
    "plt.plot(np.transpose(func_d.get_data()[x, y, z, :]))\n",
    "plt.legend(['Original', 'Detrend']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now see what `standardiz` does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_ds = nli.clean_img(func, detrend=True, standardize=True, t_r=TR)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(np.transpose(func_d.get_data()[x, y, z, :]))\n",
    "plt.plot(np.transpose(func_ds.get_data()[x, y, z, :]))\n",
    "plt.legend(['Detrend', 'Detrend+standardize']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_ds_c = nli.clean_img(func, detrend=True, standardize=True, t_r=TR,\n",
    "                          confounds='data/sub-01_ses-test_task-fingerfootlips_bold_mcf.par')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(np.transpose(func_ds.get_data()[x, y, z, :]))\n",
    "plt.plot(np.transpose(func_ds_c.get_data()[x, y, z, :]))\n",
    "plt.legend(['Det.+stand.', 'Det.+stand.-confounds']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Image visualization with `nilearn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Glass brain plotting in nilearn\n",
    "===============================\n",
    "\n",
    "See `plotting` for more plotting functionalities.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve data from Internet\n",
    "---------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import datasets\n",
    "\n",
    "localizer_dataset = datasets.fetch_localizer_button_task()\n",
    "localizer_tmap_filename = localizer_dataset.tmaps[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Glass brain plotting: whole brain sagittal cuts\n",
    "-----------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import plotting\n",
    "\n",
    "plotting.plot_glass_brain(localizer_tmap_filename, threshold=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Glass brain plotting: black backgrond\n",
    "-------------------------------------\n",
    "On a black background (option \"black_bg\"), and with only the x and\n",
    "the z view (option \"display_mode\").\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_glass_brain(\n",
    "    localizer_tmap_filename, title='plot_glass_brain',\n",
    "    black_bg=True, display_mode='xz', threshold=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Glass brain plotting: Hemispheric sagittal cuts\n",
    "-----------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_glass_brain(localizer_tmap_filename,\n",
    "                          title='plot_glass_brain with display_mode=\"lyrz\"',\n",
    "                          display_mode='lyrz', threshold=3)\n",
    "\n",
    "plotting.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Glass brain plotting in nilearn (all options)\n",
    "=============================================\n",
    "\n",
    "First part of this example goes through different options of the\n",
    ":func:`nilearn.plotting.plot_glass_brain` function (including plotting\n",
    "negative values).\n",
    "\n",
    "Second part, goes through same options but selected of the same glass brain\n",
    "function but plotting is seen with contours.\n",
    "\n",
    "See `plotting` for more plotting functionalities and\n",
    "`Section 4.3 <display_modules>` for more details about display objects\n",
    "in Nilearn.\n",
    "\n",
    "Also, see :func:`nilearn.datasets.fetch_localizer_button_task` for details\n",
    "about the plotting data and its experiments.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve the data\n",
    "------------------\n",
    "\n",
    "Nilearn comes with set of functions that download public data from Internet\n",
    "\n",
    "Let us first see where the data will be downloded and stored on our disk:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import datasets\n",
    "print('Datasets shipped with nilearn are stored in: %r' % datasets.get_data_dirs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now retrieve a motor task contrast maps corresponding to second subject\n",
    "from a localizer experiment\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmap_filenames = datasets.fetch_localizer_button_task()['tmaps']\n",
    "print(tmap_filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tmap_filenames is returned as a list. We need to take first one\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmap_filename = tmap_filenames[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demo glass brain plotting\n",
    "--------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import plotting\n",
    "\n",
    "# Whole brain sagittal cuts and map is thresholded at 3\n",
    "plotting.plot_glass_brain(tmap_filename, threshold=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a colorbar\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_glass_brain(tmap_filename, threshold=3, colorbar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Black background, and only the (x, z) cuts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_glass_brain(tmap_filename, title='plot_glass_brain',\n",
    "                          black_bg=True, display_mode='xz', threshold=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the sign of the activation with plot_abs to False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_glass_brain(tmap_filename, threshold=0, colorbar=True,\n",
    "                          plot_abs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sign of the activation and a colorbar\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_glass_brain(tmap_filename, threshold=3,\n",
    "                          colorbar=True, plot_abs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different projections for the left and right hemispheres\n",
    "---------------------------------------------------------\n",
    "\n",
    "Hemispheric sagittal cuts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_glass_brain(tmap_filename,\n",
    "                          title='plot_glass_brain with display_mode=\"lzr\"',\n",
    "                          black_bg=True, display_mode='lzr', threshold=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_glass_brain(tmap_filename, threshold=0, colorbar=True,\n",
    "                          title='plot_glass_brain with display_mode=\"lyrz\"',\n",
    "                          plot_abs=False, display_mode='lyrz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demo glass brain plotting with contours and with fillings\n",
    "---------------------------------------------------------\n",
    "To plot maps with contours, we call the plotting function into variable from\n",
    "which we can use specific display features which are inherited automatically.\n",
    "In this case, we focus on using add_contours\n",
    "First, we initialize the plotting function into \"display\" and first\n",
    "argument set to None since we want an empty glass brain to plotting the\n",
    "statistical maps with \"add_contours\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display = plotting.plot_glass_brain(None)\n",
    "# Here, we project statistical maps\n",
    "display.add_contours(tmap_filename)\n",
    "# and a title\n",
    "display.title('\"tmap_filename\" on glass brain without threshold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting with `filled=True` implies contours with fillings. Here, we are not\n",
    "specifying levels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display = plotting.plot_glass_brain(None)\n",
    "# Here, we project statistical maps with filled=True\n",
    "display.add_contours(tmap_filename, filled=True)\n",
    "# and a title\n",
    "display.title('Same map but with fillings in the contours')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we input specific level (cut-off) in the statistical map. In other way,\n",
    "we are thresholding our statistical map\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we set the threshold using parameter called `levels` with value given\n",
    "# in a list and choosing color to Red.\n",
    "display = plotting.plot_glass_brain(None)\n",
    "display.add_contours(tmap_filename, levels=[3.], colors='r')\n",
    "display.title('\"tmap_filename\" on glass brain with threshold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting with same demonstration but inlcudes now filled=True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display = plotting.plot_glass_brain(None)\n",
    "display.add_contours(tmap_filename, filled=True, levels=[3.], colors='r')\n",
    "display.title('Same demonstration but using fillings inside contours')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting with black background, `black_bg` should be set with\n",
    "`plot_glass_brain`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can set black background using black_bg=True\n",
    "display = plotting.plot_glass_brain(None, black_bg=True)\n",
    "display.add_contours(tmap_filename, levels=[3.], colors='g')\n",
    "display.title('\"tmap_filename\" on glass brain with black background')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Black background plotting with filled in contours\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display = plotting.plot_glass_brain(None, black_bg=True)\n",
    "display.add_contours(tmap_filename, filled=True, levels=[3.], colors='g')\n",
    "display.title('Glass brain with black background and filled in contours')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display contour projections in both hemispheres\n",
    "-------------------------------------------------\n",
    "Key argument to vary here is `display_mode` for hemispheric plotting\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, display_mode is chosen as 'lr' for both hemispheric plots\n",
    "display = plotting.plot_glass_brain(None, display_mode='lr')\n",
    "display.add_contours(tmap_filename, levels=[3.], colors='r')\n",
    "display.title('\"tmap_filename\" on glass brain only \"l\" \"r\" hemispheres')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filled contours in both hemispheric plotting, just by adding filled=True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display = plotting.plot_glass_brain(None, display_mode='lr')\n",
    "display.add_contours(tmap_filename, filled=True, levels=[3.], colors='r')\n",
    "display.title('Filled contours on glass brain only \"l\" \"r\" hemispheres')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With positive and negative sign of activations with `plot_abs` in\n",
    "`plot_glass_brain`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default parameter `plot_abs` is True and sign of activations can be\n",
    "# displayed by changing `plot_abs` to False\n",
    "display = plotting.plot_glass_brain(None, plot_abs=False, display_mode='lzry')\n",
    "display.add_contours(tmap_filename)\n",
    "display.title(\"Contours with both sign of activations without threshold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, adding just filled=True to get positive and negative sign activations\n",
    "with fillings in the contours\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display = plotting.plot_glass_brain(None, plot_abs=False, display_mode='lzry')\n",
    "display.add_contours(tmap_filename, filled=True)\n",
    "display.title(\"Filled contours with both sign of activations without threshold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying both signs (positive and negative) of activations with threshold\n",
    "meaning thresholding by adding an argument `levels` in add_contours.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "display = plotting.plot_glass_brain(None, plot_abs=False, display_mode='lzry')\n",
    "\n",
    "# In add_contours,\n",
    "# we give two values through the argument `levels` which corresponds to the\n",
    "# thresholds of the contour we want to draw: One is positive and the other one\n",
    "# is negative. We give a list of `colors` as argument to associate a different\n",
    "# color to each contour. Additionally, we also choose to plot contours with\n",
    "# thick line widths, For linewidths one value would be enough so that same\n",
    "# value is used for both contours.\n",
    "display.add_contours(tmap_filename, levels=[-2.8, 3.], colors=['b', 'r'],\n",
    "                     linewidths=4.)\n",
    "display.title('Contours with sign of activations with threshold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same display demonstration as above but just adding filled=True to get\n",
    "fillings inside the contours.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unlike in previous plot, here we specify each sign at a time. We call negative\n",
    "# values display first followed by positive values display.\n",
    "\n",
    "# First, we fetch our display object with same parametes used as above\n",
    "display = plotting.plot_glass_brain(None, plot_abs=False, display_mode='lzry')\n",
    "\n",
    "# Second, we plot negative sign of activation with levels given as negative\n",
    "# activation value in a list. Upper bound should be kept to -infinity\n",
    "display.add_contours(tmap_filename, filled=True, levels=[-np.inf, -2.8],\n",
    "                     colors='b')\n",
    "# Next, within same plotting object we plot positive sign of activation\n",
    "display.add_contours(tmap_filename, filled=True, levels=[3.], colors='r')\n",
    "display.title('Now same plotting but with filled contours')\n",
    "\n",
    "# Finally, displaying them\n",
    "plotting.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "More plotting tools from nilearn\n",
    "================================\n",
    "\n",
    "In this example, we demonstrate how to use plotting options from\n",
    "nilearn essential in visualizing brain image analysis results.\n",
    "\n",
    "We emphasize the use of parameters such as `display_mode` and `cut_coords`\n",
    "with plotting function :func:`nilearn.plotting.plot_stat_map`. Also,\n",
    "we show how to use various features such as `add_edges`, `add_contours`,\n",
    "`add_markers` essential in visualizing regions of interest images or\n",
    "mask images overlaying on subject specific anatomical/EPI image.\n",
    "The display features shown here are inherited from the\n",
    ":class:`nilearn.plotting.displays.OrthoSlicer` class.\n",
    "\n",
    "The parameter `display_mode` is used to draw brain slices along given\n",
    "specific directions, where directions can be one of 'ortho',\n",
    "'x', 'y', 'z', 'xy', 'xz', 'yz'. whereas parameter `cut_coords`\n",
    "is used to specify a limited number of slices to visualize along given\n",
    "specific slice direction. The parameter `cut_coords` can also be used\n",
    "to draw the specific cuts in the slices by giving its particular\n",
    "coordinates in MNI space accordingly with particular slice direction.\n",
    "This helps us point to the activation specific location of the brain slices.\n",
    "\n",
    "See `plotting` for more details.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we retrieve data from nilearn provided (general-purpose) datasets\n",
    "-------------------------------------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import datasets\n",
    "\n",
    "# haxby dataset to have anatomical image, EPI images and masks\n",
    "haxby_dataset = datasets.fetch_haxby()\n",
    "haxby_anat_filename = haxby_dataset.anat[0]\n",
    "haxby_mask_filename = haxby_dataset.mask_vt[0]\n",
    "haxby_func_filename = haxby_dataset.func[0]\n",
    "\n",
    "# localizer dataset to have contrast maps\n",
    "localizer_dataset = datasets.fetch_localizer_button_task(get_anats=True)\n",
    "localizer_anat_filename = localizer_dataset.anats[0]\n",
    "localizer_tmap_filename = localizer_dataset.tmaps[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we show from here how to visualize the retrieved datasets using plotting\n",
    "tools from nilearn.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing in - 'sagittal', 'coronal' and 'axial' with given coordinates\n",
    "-------------------------------------------------------------------------\n",
    "The first argument is a path to the filename of a constrast map,\n",
    "optional argument `display_mode` is given as string 'ortho' to visualize\n",
    "the map in three specific directions xyz and the optional `cut_coords`\n",
    "argument, is here a list of integers denotes coordinates of each slice\n",
    "in the order [x, y, z]. By default the `colorbar` argument is set to True\n",
    "in plot_stat_map.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_stat_map(localizer_tmap_filename, display_mode='ortho',\n",
    "                       cut_coords=[36, -27, 60],\n",
    "                       title=\"display_mode='ortho', cut_coords=[36, -27, 60]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing in - single view 'axial' with number of cuts=5\n",
    "-----------------------------------------------------------\n",
    "In this type of visualization, the `display_mode` argument is given as\n",
    "string 'z' for axial direction and `cut_coords` as integer 5 without a\n",
    "list implies that number of cuts in the slices should be maximum of 5.\n",
    "The coordinates to cut the slices are selected automatically\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_stat_map(localizer_tmap_filename, display_mode='z', cut_coords=5,\n",
    "                       title=\"display_mode='z', cut_coords=5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing in - single view 'sagittal' with only two slices\n",
    "-------------------------------------------------------------\n",
    "In this type, `display_mode` should be given as string 'x' for sagittal\n",
    "view and coordinates should be given as integers in a list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_stat_map(localizer_tmap_filename, display_mode='x',\n",
    "                       cut_coords=[-36, 36],\n",
    "                       title=\"display_mode='x', cut_coords=[-36, 36]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing in - 'coronal' view with single cut\n",
    "------------------------------------------------\n",
    "For coronal view, `display_mode` is given as string 'y' and `cut_coords`\n",
    "as integer 1 not as a list for single cut. The coordinates are selected\n",
    "automatically\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_stat_map(localizer_tmap_filename, display_mode='y', cut_coords=1,\n",
    "                       title=\"display_mode='y', cut_coords=1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing without a colorbar on the right side\n",
    "-------------------------------------------------\n",
    "The argument `colorbar` should be given as False to show plots without\n",
    "a colorbar on the right side.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_stat_map(localizer_tmap_filename, display_mode='z',\n",
    "                       cut_coords=1, colorbar=False,\n",
    "                       title=\"display_mode='z', cut_coords=1, colorbar=False\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize in - two views 'sagittal' and 'axial' with given coordinates\n",
    "-------------------------------------------------------------------------\n",
    "argument display_mode='xz' where 'x' for sagittal and 'z' for axial view.\n",
    "argument `cut_coords` should match with input number of views therefore two\n",
    "integers should be given in a list to select the slices to be displayed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_stat_map(localizer_tmap_filename, display_mode='xz',\n",
    "                       cut_coords=[36, 60],\n",
    "                       title=\"display_mode='xz', cut_coords=[36, 60]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing the views to 'coronal', 'sagittal' views with coordinates\n",
    "-------------------------------------------------------------------\n",
    "display_mode='yx' for coronal and saggital view and coordinates will be\n",
    "assigned in the order of direction as [x, y, z]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_stat_map(localizer_tmap_filename, display_mode='yx',\n",
    "                       cut_coords=[-27, 36],\n",
    "                       title=\"display_mode='yx', cut_coords=[-27, 36]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, views are changed to 'coronal' and 'axial' views with coordinates\n",
    "-----------------------------------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_stat_map(localizer_tmap_filename, display_mode='yz',\n",
    "                       cut_coords=[-27, 60],\n",
    "                       title=\"display_mode='yz', cut_coords=[-27, 60]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demonstrating various display features\n",
    "---------------------------------------\n",
    "In second part, we switch to demonstrating various features add_* from\n",
    "nilearn where each specific feature will be helpful in projecting brain\n",
    "imaging results for further interpretation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import image processing tool for basic processing of functional brain image\n",
    "from nilearn import image\n",
    "\n",
    "# Compute voxel-wise mean functional image across time dimension. Now we have\n",
    "# functional image in 3D assigned in mean_haxby_img\n",
    "mean_haxby_img = image.mean_img(haxby_func_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Showing how to use `add_edges`\n",
    "------------------------------\n",
    "Now let us see how to use `add_edges`, method useful for checking\n",
    "coregistration by overlaying anatomical image as edges (red) on top of\n",
    "mean functional image (background), both being of same subject.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we call the `plot_anat` plotting function, with a background image\n",
    "# as first argument, in this case the mean fMRI image.\n",
    "\n",
    "display = plotting.plot_anat(mean_haxby_img, title=\"add_edges\")\n",
    "\n",
    "# We are now able to use add_edges method inherited in plotting object named as\n",
    "# display. First argument - anatomical image  and by default edges will be\n",
    "# displayed as red 'r', to choose different colors green 'g' and  blue 'b'.\n",
    "display.add_edges(haxby_anat_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to use `add_contours`\n",
    "-------------------------\n",
    "Plotting outline of the mask (red) on top of the mean EPI image with\n",
    "`add_contours`. This method is useful for region specific interpretation\n",
    "of brain images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As seen before, we call the `plot_anat` function with a background image\n",
    "# as first argument, in this case again the mean fMRI image and argument\n",
    "# `cut_coords` as list for manual cut with coordinates pointing at masked\n",
    "# brain regions\n",
    "display = plotting.plot_anat(mean_haxby_img, title=\"add_contours\",\n",
    "                             cut_coords=[-34, -39, -9])\n",
    "# Now use `add_contours` in display object with the path to a mask image from\n",
    "# the Haxby dataset as first argument and argument `levels` given as list\n",
    "# of values to select particular level in the contour to display and argument\n",
    "# `colors` specified as red 'r' to see edges as red in color.\n",
    "# See help on matplotlib.pyplot.contour to use more options with this method\n",
    "display.add_contours(haxby_mask_filename, levels=[0.5], colors='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting outline of the mask (blue) with color fillings using same method\n",
    "`add_contours`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display = plotting.plot_anat(mean_haxby_img,\n",
    "                             title=\"add_contours with filled=True\",\n",
    "                             cut_coords=[-34, -39, -9])\n",
    "\n",
    "# By default, no color fillings will be shown using `add_contours`. To see\n",
    "# contours with color fillings use argument filled=True. contour colors are\n",
    "# changed to blue 'b' with alpha=0.7 sets the transparency of color fillings.\n",
    "# See help on matplotlib.pyplot.contourf to use more options given that filled\n",
    "# should be True\n",
    "display.add_contours(haxby_mask_filename, filled=True, alpha=0.7,\n",
    "                     levels=[0.5], colors='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting seeds using `add_markers`\n",
    "----------------------------------\n",
    "Plotting seed regions of interest as spheres using new feature `add_markers`\n",
    "with MNI coordinates of interest.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display = plotting.plot_anat(mean_haxby_img, title=\"add_markers\",\n",
    "                             cut_coords=[-34, -39, -9])\n",
    "\n",
    "# Coordinates of seed regions should be specified in first argument and second\n",
    "# argument `marker_color` denotes color of the sphere in this case yellow 'y'\n",
    "# and third argument `marker_size` denotes size of the sphere\n",
    "coords = [(-34, -39, -9)]\n",
    "display.add_markers(coords, marker_color='y', marker_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, saving the plots to file with two different ways\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contrast maps plotted with function `plot_stat_map` can be saved using an\n",
    "# inbuilt parameter output_file as filename + .extension as string. Valid\n",
    "# extensions are .png, .pdf, .svg\n",
    "plotting.plot_stat_map(localizer_tmap_filename,\n",
    "                       title='Using plot_stat_map output_file',\n",
    "                       output_file='plot_stat_map.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way of saving plots is using 'savefig' option from display object\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display = plotting.plot_stat_map(localizer_tmap_filename,\n",
    "                                 title='Using display savefig')\n",
    "display.savefig('plot_stat_map_from_display.png')\n",
    "# In non-interactive settings make sure you close your displays\n",
    "display.close()\n",
    "\n",
    "plotting.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Making a surface plot of a 3D statistical map\n",
    "=============================================\n",
    "\n",
    "project a 3D statistical map onto a cortical mesh using\n",
    ":func:`nilearn.surface.vol_to_surf`. Display a surface plot of the projected\n",
    "map using :func:`nilearn.plotting.plot_surf_stat_map`.\n",
    "\n",
    "NOTE: Example needs matplotlib version higher than 1.3.1.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a statistical map\n",
    "---------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import datasets\n",
    "\n",
    "localizer_dataset = datasets.fetch_localizer_button_task()\n",
    "localizer_tmap = localizer_dataset.tmaps[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a cortical mesh\n",
    "-------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fsaverage = datasets.fetch_surf_fsaverage5()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample the 3D data around each node of the mesh\n",
    "-----------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import surface\n",
    "\n",
    "texture = surface.vol_to_surf(localizer_tmap, fsaverage.pial_right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the result\n",
    "---------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import plotting\n",
    "\n",
    "plotting.plot_surf_stat_map(fsaverage.infl_right, texture, hemi='right',\n",
    "                            title='Surface right hemisphere',\n",
    "                            threshold=1., bg_map=fsaverage.sulc_right,\n",
    "                            cmap='cold_hot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot 3D image for comparison\n",
    "----------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_glass_brain(localizer_tmap, display_mode='r', plot_abs=False,\n",
    "                          title='Glass brain', threshold=2.)\n",
    "\n",
    "plotting.plot_stat_map(localizer_tmap, display_mode='x', threshold=1.,\n",
    "                       cut_coords=range(0, 51, 10), title='Slices')\n",
    "\n",
    "plotting.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Don't forget tal's visualization\n",
    "https://github.com/neurohackweek/visualization-in-python/blob/master/visualization-in-python.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Machine learning with `nilearn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "It also simplifies a number of common tasks with neuroimages. For example, we can recreate the mean EPI image we just made in one line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nilearn as nl\n",
    "import nilearn.plotting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = nl.image.mean_img('/data/ds000114/sub-01/ses-test/func/sub-01_ses-test_task-linebisection_bold.nii.gz')\n",
    "print(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nilearn images are just nibabel images! But notice that we didn't have to copy the affine or header. Nilearn does its best to keep your data and metadata together.\n",
    "\n",
    "Let's verify that both methods produced the same image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array_equal(mean_epi.get_data(), img.get_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array_equal(mean_epi.affine, img.affine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting images\n",
    "\n",
    "Nilearn has a variety of plotting facilities. `plot_epi` shows functional images in a high-contrast color scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nl.plotting.plot_epi(mean_epi, cut_coords=(0, 0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(nl.plotting.plot_epi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "## Exercise 4:\n",
    "\n",
    "Using the help output from above, redraw the mean_epi image as a set of 5 slices spanning front to back. Suppress the background using the `vmin` option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "nl.plotting.plot_epi(mean_epi, display_mode='y', cut_coords=5, vmin=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the mean_epi image slices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot anatomical images. Let's show the FreeSurfer `aseg` segmentation over the T1 image we loaded earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nl.plotting.plot_anat(t1, dim=-1, cut_coords=(0, 0, 0))\n",
    "nl.plotting.plot_roi('/data/ds000114/derivatives/freesurfer/sub-01/mri/aseg.mgz', t1,\n",
    "                     dim=-1, cut_coords=(0, 0, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But the overlay above looks misaligned. That's because this dataset uses a derived T1 image as input to `FreeSurfer`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "## Exercise 5:\n",
    "\n",
    "The T1 image used for FreeSurfer is at `/data/ds000114/derivatives/fmriprep/sub-01/anat/sub-01_t1w_preproc.nii.gz`. Redraw the above plot using the correct background T1 image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "t1_correct = nib.load('/data/ds000114/derivatives/fmriprep/sub-01/anat/sub-01_t1w_preproc.nii.gz')\n",
    "nl.plotting.plot_anat(t1_correct, dim=-1, cut_coords=(0, 0, 0))\n",
    "nl.plotting.plot_roi('/data/ds000114/derivatives/freesurfer/sub-01/mri/aseg.mgz', t1_correct,\n",
    "                     dim=-1, cut_coords=(0, 0, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that nilearn will accept an image or a filename equally. Also recall that `t1` was a NIfTI-1 image, while `aseg` is in a FreeSurfer `.mgz` file. Nilearn takes advantage of the common interface (data-affine-header) that nibabel provides for these different formats, and makes correctly aligned overlays.\n",
    "\n",
    "This means we can use nilearn to verify alignment, for example when testing a new algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_algorithm(image):\n",
    "    # Just mess up the affine\n",
    "    bad_affine = image.affine.copy()\n",
    "    bad_affine[:, :2] = mask.affine[:, 1::-1]\n",
    "    return image.__class__(image.get_data(), bad_affine, mask.header)\n",
    "\n",
    "mask = nl.image.math_img(\"img > 0\", img='/data/ds000114/derivatives/freesurfer/sub-01/mri/brainmask.auto.mgz')\n",
    "new_mask = new_algorithm(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "## Exercise 6:\n",
    "\n",
    "Plot the original and messed up mask on the same background image with two colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "t1_correct = nib.load('/data/ds000114/derivatives/fmriprep/sub-01/anat/sub-01_t1w_preproc.nii.gz')\n",
    "nl.plotting.plot_roi(mask, t1_correct, dim=-1, cut_coords=(0, 0, 0), cmap='Greens_r')\n",
    "nl.plotting.plot_roi(new_mask, t1_correct, dim=-1, cut_coords=(0, 0, 0), cmap='Reds_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nilearn can also plot results directly in MNI space using an outline. This uses the function `nl.plotting.plot_glass_brain`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = nl.image.mean_img('/data/ds000114/derivatives/fmriprep/sub-01/ses-test/func/sub-01_ses-test_task-fingerfootlips_bold_space-mni152nlin2009casym_preproc.nii.gz')\n",
    "nl.plotting.plot_glass_brain(img, threshold=1000, colorbar=True, display_mode='lyrz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting surfaces\n",
    "\n",
    "Nilearn has recently added surface plotting to its repertoire. Let's examine the gray/white boundary and pial surfaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "white = '/data/ds000114/derivatives/freesurfer/sub-01/surf/lh.white'\n",
    "pial = '/data/ds000114/derivatives/freesurfer/sub-01/surf/lh.pial'\n",
    "sulc = '/data/ds000114/derivatives/freesurfer/sub-01/surf/lh.sulc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = nl.plotting.plot_surf(white, bg_map=sulc)\n",
    "_ = nl.plotting.plot_surf(pial, bg_map=sulc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common step in surface pipelines is to create a surface halfway between the white and pial surface (often called the \"midthickness\" or \"graymid\" surface). The fastest, easiest, possibly wrong (but in practice fine) way to get this surface is to take the mean of the coordinates of the corresponding vertices on the white and pial surface. We can do this straightforwardly in nibabel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wcoords, wfaces, wmeta = nb.freesurfer.read_geometry(white, read_metadata=True)\n",
    "pcoords, pfaces = nb.freesurfer.read_geometry(white, read_metadata=False)\n",
    "\n",
    "# Make sure these surfaces actually do correspond\n",
    "assert np.array_equal(wfaces, pfaces)\n",
    "\n",
    "(wcoords, wfaces, wmeta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that this is not an image object, just a tuple of coordinates, faces, and an optional metadata dictionary. And it's an example of a file nibabel doesn't handle with `nibabel.load()`.\n",
    "\n",
    "Coordinates are the (x, y, z) coordinates of each vertex; faces are a triangle composed of three vertices, and the metadata describes the provenance and alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcoords = (wcoords + pcoords) / 2\n",
    "# nilearn can be pretty picky about names, so fool it into reading this as a surface file\n",
    "graymid = os.path.join(out_dir, 'lh.white')\n",
    "nb.freesurfer.write_geometry(graymid, gcoords, wfaces, volume_info=wmeta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = nl.plotting.plot_surf(graymid, bg_map=sulc, view='lateral')\n",
    "_ = nl.plotting.plot_surf(graymid, bg_map=sulc, view='medial')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks reasonable. Let's overlay it with the `aparc` parcellation. Nilearn doesn't handle these well yet, so again, we'll load with nibabel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aparc = nb.freesurfer.read_annot('/data/ds000114/derivatives/freesurfer/sub-01/label/lh.aparc.annot')\n",
    "\n",
    "_ = nl.plotting.plot_surf_roi(os.path.join(out_dir, 'lh.white'), aparc[0], bg_map=sulc, view='lateral')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "shown",
    "solution2_first": true
   },
   "source": [
    "## Exercise 7:\n",
    "\n",
    "Plot the aparc overlay of the right hemisphere of subject 2 after calculating the mid-thickness geometry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "shown"
   },
   "outputs": [],
   "source": [
    "white = '/data/ds000114/derivatives/freesurfer/sub-02/surf/rh.white'\n",
    "pial = '/data/ds000114/derivatives/freesurfer/sub-02/surf/rh.pial'\n",
    "sulc = '/data/ds000114/derivatives/freesurfer/sub-02/surf/rh.sulc'\n",
    "\n",
    "wcoords, wfaces, wmeta = nb.freesurfer.read_geometry(white, read_metadata=True)\n",
    "pcoords, pfaces = nb.freesurfer.read_geometry(white, read_metadata=False)\n",
    "\n",
    "gcoords = (wcoords + pcoords) / 2\n",
    "# nilearn can be pretty picky about names, so fool it into reading this as a surface file\n",
    "graymid = os.path.join(out_dir, 'rh.white')\n",
    "nb.freesurfer.write_geometry(graymid, gcoords, wfaces, volume_info=wmeta)\n",
    "\n",
    "aparc = nb.freesurfer.read_annot('/data/ds000114/derivatives/freesurfer/sub-02/label/rh.aparc.annot')\n",
    "\n",
    "_ = nl.plotting.plot_surf_roi(os.path.join(out_dir, 'rh.white'), aparc[0], bg_map=sulc, view='lateral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point to data\n",
    "\n",
    "# Load data\n",
    "\n",
    "# Calculate mid thickness\n",
    "\n",
    "# Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review\n",
    "\n",
    "We've explored the visualization capabilities of nilearn, which include the ability to plot BOLD images, ROIs and masks overlaid on anatomical images and surfaces. Additionally, we've used nilearn's image manipulation utilities (`mean_img`, and `math_img`) to quickly create new, valid images, and considered the dangers of destroying your affine matrix. Finally, we created our own surface using nibabel's FreeSurfer utilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Machine learning with `nilearn`\n",
    "\n",
    "Although nilearn's visualizations are quite nice, its primary purpose was to make running machine learning algorithms on neuroimaging data as simple as possible. In this sense, it is a bridge between nibabel and [scikit-learn](http://scikit-learn.org/stable/). On the one hand, it reformats images to be easily passed to scikit-learn, and on the other, it reformats the results to produce valid nibabel images.\n",
    "\n",
    "This section is heavily based on the [nilearn decoding tutorial](https://nilearn.github.io/auto_examples/plot_decoding_tutorial.html).\n",
    "\n",
    "The dataset should be pre-loaded for you on your docker image. Go ahead and verify:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nilearn.datasets\n",
    "import nilearn.input_data\n",
    "\n",
    "haxby_dataset = nl.datasets.fetch_haxby(data_dir='data')\n",
    "\n",
    "bold = haxby_dataset.func[0]\n",
    "mask = haxby_dataset.mask_vt[0]\n",
    "anat = haxby_dataset.anat[0]\n",
    "labels = haxby_dataset.session_target[0]\n",
    "\n",
    "!nib-ls $bold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masking and Un-masking data\n",
    "\n",
    "We need our functional data in a 2D, sample-by-voxel matrix. To get that, we'll select a set of voxels in VT cortex defined by `mask`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nl.plotting.plot_roi(mask, anat, cmap='Paired', dim=-.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`NiftiMasker` is an object that applies a mask to a dataset and returns the masked voxels as a vector at each time point.\n",
    "`standardize=True` z-scores each voxel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masker = nl.input_data.NiftiMasker(mask_img=mask, standardize=True)\n",
    "samples = masker.fit_transform(bold)\n",
    "print(samples)\n",
    "print(samples.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To recover the original data shape (giving us a masked and z-scored BOLD series), we simply use the masker's inverse transform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_epi = masker.inverse_transform(samples)\n",
    "\n",
    "# For visualization... not a useful statistic\n",
    "max_zscores = nl.image.math_img(\"np.abs(img).max(axis=3)\", img=masked_epi)\n",
    "nl.plotting.plot_stat_map(max_zscores, bg_img=anat, dim=-.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple MVPA Example\n",
    "\n",
    "Multi-voxel pattern analysis (MVPA) is a general term for techniques that contrast conditions over multiple voxels. It's very common to use machine learning models to generate statistics of interest.\n",
    "\n",
    "In this case, we'll use the response patterns of voxels in VT cortex to predict the identity of the stimulus this subject was presented with. We'll use a support vector classifier (SVC) and leave-one-run-out cross-validation.\n",
    "\n",
    "This section is not intended to teach machine learning, but to demonstrate a simple nilearn pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import LeaveOneGroupOut, cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels file contains metadata for each volume, indicating the stimulus type and run number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 5 $labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `np.recfromcsv()`, we can refer to each column of this file by its header."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrs = np.recfromcsv(labels, delimiter=\" \")\n",
    "stimuli, runs = attrs['labels'], attrs['chunks']\n",
    "print(attrs.shape, np.unique(stimuli), np.unique(runs), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity, let's consider a two-class problem. Select the BOLD samples associated with bottles and shoes. We'll also need to select the corresponding stimuli and run numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_mask = (stimuli == b'bottle') | (stimuli == b'shoe')\n",
    "\n",
    "samples_2class = samples[condition_mask]\n",
    "stimuli_2class = stimuli[condition_mask]\n",
    "runs_2class = runs[condition_mask]\n",
    "\n",
    "samples_2class.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leave-one-run-out cross-validation trains on `(n - 1)` runs, and classifies the remaining run, for each run. Mean (across runs) cross-validation accuracy is a common statistic for classification-based MVPA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(kernel='linear')\n",
    "cva = cross_val_score(estimator=svc,\n",
    "                      X=samples_2class,\n",
    "                      y=stimuli_2class,\n",
    "                      groups=runs_2class,\n",
    "                      cv=LeaveOneGroupOut(),\n",
    "                      n_jobs=-1)\n",
    "print(cva, cva.mean(), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another approach is to train a classifier on all of the data. This isn't useful for predicting, but we can read out the weight assigned to each voxel, giving a measure of its correlation with the stimulus type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc.fit(samples_2class, stimuli_2class)\n",
    "svc.coef_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have a value for each voxel, we can simply map this back to the volume using our `masker`, and visualize the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_vol = masker.inverse_transform(svc.coef_)\n",
    "nl.plotting.plot_stat_map(coef_vol, bg_img=anat, dim=-.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review\n",
    "\n",
    "In this section, we explored nilearn's tools for interfacing neuroimaging data and machine learning algorithms. Central to this is the concept of the masker, which moves data from 4-dimensional BOLD time series to a 2-dimensional series of feature vectors, and can map resulting statistics back into the original BOLD volume. We used leave-one-run-out cross-validation to explore 2-class support vector classification, and mapped feature weights back into the volume."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "In this tutorial, we've explored loading, saving and visualizing neuroimages, as well as how nibabel and nilearn can make some more sophisticated manipulations easy. At this point, you should be able to inspect and plot most images you encounter, as well as make modifications while preserving the alignment. If we've made it through the final section, you've also seen the basic workflow for performing a wide range of statistical analyses on BOLD time series in nilearn."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
